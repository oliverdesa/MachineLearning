{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.metrics import accuracy_score\n",
        "from graphviz import Source\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EIh9Ayf-Jdfs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "lxlmi6K-vLeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A)\n",
        "\n",
        "# Function to read data from csv and split it into train/validation/test groups\n",
        "def load_data(csvFile):\n",
        "\n",
        "    # read csv to dataframe and replace NAs w/ 0\n",
        "    df = pd.read_csv(csvFile)\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    # Define the labelled target column and drop it from the independant variables\n",
        "    Target = df['Dataset']\n",
        "    df = df.drop(columns = ['Dataset'])\n",
        "\n",
        "    # Convert the Gender data to quantitative values\n",
        "    df['Gender'].replace(['Male', 'Female'],\n",
        "                        [0, 1], inplace=True)\n",
        "\n",
        "    # Generate train test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df, Target, test_size=0.3,\n",
        "                                                        random_state = 1)\n",
        "\n",
        "    # Split test data further into test/validation\n",
        "    X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.3,\n",
        "                                                        random_state = 1)\n",
        "\n",
        "    return(X_train, y_train, X_valid, y_valid, X_test, y_test)"
      ],
      "metadata": {
        "id": "hhQFl9Gc42HB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data for use\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = load_data('hw1_data.csv')\n",
        "\n",
        "#test print to check if data was properly split\n",
        "#print(len(X_train), len(y_train), len(X_valid), len(y_valid), len(X_test), len(y_test))"
      ],
      "metadata": {
        "id": "wo4gBCCD5NQL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# B)\n",
        "\n",
        "def select_knn_model(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
        "\n",
        "  # Define K-values from 1 - 20\n",
        "  k_values = list(range(1,21))\n",
        "\n",
        "  # Initial empty lists to store generated accuracies\n",
        "  ValidAccuracies = []\n",
        "  TrainAccuracies = []\n",
        "\n",
        "  # For each k in range 1-20, fit the model on the training data and predict \n",
        "  # training and validation values, storing and plotting the respective accuracies\n",
        "  for k in k_values:\n",
        "      model = KNeighborsClassifier(n_neighbors=k)\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      train_pred = model.predict(X_train)\n",
        "\n",
        "      TrainAccuracies.append(accuracy_score(y_train, train_pred))\n",
        "\n",
        "      val_pred = model.predict(X_valid)\n",
        "\n",
        "      ValidAccuracies.append(accuracy_score(y_valid, val_pred))\n",
        "\n",
        "  # Cat the results into a dataframe for easier visualizaiton\n",
        "  kAccuracies = pd.DataFrame(zip(k_values, TrainAccuracies, ValidAccuracies), \n",
        "                            columns = ['K values', 'Train Accuracy', 'Validation Accuracy'])\n",
        "\n",
        "  # Plot the training accuracy for each value of k\n",
        "  plt.plot(range(1, 21), kAccuracies['Train Accuracy'], 'b-', label='Training Accuracy')\n",
        "\n",
        "  # Plot the validation accuracy for each value of k\n",
        "  plt.plot(range(1, 21), kAccuracies['Validation Accuracy'], 'r-', label='Validation Accuracy')\n",
        "\n",
        "  plt.xlabel(\"k\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.title(\"Accuracy for k-NN\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  return(kAccuracies)"
      ],
      "metadata": {
        "id": "WG0XKhKl-8jI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Knn model function on the split data\n",
        "kAccuracies = select_knn_model(X_train, y_train, X_valid, y_valid, X_test, y_test)"
      ],
      "metadata": {
        "id": "ek8Nzh3DqejQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best k-value selected and used on test data\n",
        "\n",
        "# Initiate the model with a k-value corresponding to the highest validation accuracy\n",
        "model = KNeighborsClassifier(n_neighbors=\n",
        "                             kAccuracies['Validation Accuracy'].idxmax() + 1)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# employ the model on the test data\n",
        "test_pred = model.predict(X_test)\n",
        "\n",
        "# Compute the accuracy score for the test predictions\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "print(test_accuracy)\n",
        "\n",
        "# The model with a k value corresponding to the highest validation accuracy\n",
        "# achieves an accuracy score of ~0.71311 on the test data"
      ],
      "metadata": {
        "id": "ovgXPijNDtAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C)\n",
        "\n",
        "def select_knn_model_cos(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
        "\n",
        " # Define K-values from 1 - 20\n",
        "  k_values = list(range(1,21))\n",
        "\n",
        "  # Initial empty lists to store generated accuracies\n",
        "  ValidAccuracies = []\n",
        "  TrainAccuracies = []\n",
        "\n",
        "  # For each k in range 1-20 using the metric \"cosine\", fit the model on the training\n",
        "  # data and predict training and validation values, storing and plotting the \n",
        "  # respective accuracies\n",
        "  for k in k_values:\n",
        "      model = KNeighborsClassifier(n_neighbors=k, metric = 'cosine')\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      train_pred = model.predict(X_train)\n",
        "\n",
        "      TrainAccuracies.append(accuracy_score(y_train, train_pred))\n",
        "\n",
        "      val_pred = model.predict(X_valid)\n",
        "\n",
        "      ValidAccuracies.append(accuracy_score(y_valid, val_pred))\n",
        "\n",
        "  # Cat the results into a dataframe for easier visualizaiton\n",
        "  kAccuracies = pd.DataFrame(zip(k_values, TrainAccuracies, ValidAccuracies), \n",
        "                            columns = ['K values', 'Train Accuracy', 'Validation Accuracy'])\n",
        "\n",
        "  # Plot the training accuracy for each value of k\n",
        "  plt.plot(range(1, 21), kAccuracies['Train Accuracy'], 'b-', label='Training Accuracy')\n",
        "\n",
        "  # Plot the validation accuracy for each value of k\n",
        "  plt.plot(range(1, 21), kAccuracies['Validation Accuracy'], 'r-', label='Validation Accuracy')\n",
        "\n",
        "  plt.xlabel(\"k\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.title(\"Accuracy for k-NN\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  return(kAccuracies)"
      ],
      "metadata": {
        "id": "NvRN1H9Z-agY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Knn model with cosine metric on the split data\n",
        "kAccuracies = select_knn_model_cos(X_train, y_train, X_valid, y_valid, X_test, y_test)"
      ],
      "metadata": {
        "id": "m-at1lBctKDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "gmxv_4aTvWk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A) \n",
        "\n",
        "def train_decision_tree(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    \n",
        "    # Create an instance of the DecisionTreeClassifier class\n",
        "    dt = DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_leaf=1)\n",
        "    \n",
        "    # Fit the model to the training data\n",
        "    dt.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict the labels for train, validation and test set\n",
        "    y_train_pred = dt.predict(X_train)\n",
        "    y_val_pred = dt.predict(X_val)\n",
        "    y_test_pred = dt.predict(X_test)\n",
        "    \n",
        "    # Compute the accuracy for train, validation and test set\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    val_acc = accuracy_score(y_val, y_val_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    \n",
        "    # Print the results\n",
        "    print(\"Train Accuracy: {:.4f}\".format(train_acc))\n",
        "    print(\"Validation Accuracy: {:.4f}\".format(val_acc))\n",
        "    print(\"Test Accuracy: {:.4f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "z1nFzkzMwDBj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_decision_tree(X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
        "\n",
        "# The model is overfitting, however adjusting min_samples_leaf lowers Train \n",
        "# Accuracy, but not Test accuracy\n",
        "\n",
        "# min_smaples_leaf = 1:\n",
        "# Train Accuracy: 1.0000\n",
        "# Validation Accuracy: 0.7358\n",
        "# Test Accuracy: 0.5902\n",
        "\n",
        "# min_smaples_leaf = 2:\n",
        "# Train Accuracy: 0.9485\n",
        "# Validation Accuracy: 0.6981\n",
        "# Test Accuracy: 0.5902\n",
        "\n",
        "# min_smaples_leaf = 3:\n",
        "# Train Accuracy: 0.9265\n",
        "# Validation Accuracy: 0.6981\n",
        "# Test Accuracy: 0.5738"
      ],
      "metadata": {
        "id": "1_rAYKGawcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# B)\n",
        "\n",
        "feature_names = ['Age',\t'Gender',\t'Total_Bilirubin',\t'Direct_Bilirubin',\n",
        "                 'Alkaline_Phosphotase',\t'Alamine_Aminotransferase',\n",
        "                 'Aspartate_Aminotransferase',\t'Total_Protiens',\t'Albumin',\n",
        "                 'Albumin_and_Globulin_Ratio']\n",
        "\n",
        "dt = DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_leaf=1)    \n",
        "\n",
        "# Fit the model to the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for train, validation and test set\n",
        "# y_train_pred = dt.predict(X_train)\n",
        "# y_val_pred = dt.predict(X_val)\n",
        "# y_test_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute the accuracy for train, validation and test set\n",
        "# train_acc = accuracy_score(y_train, y_train_pred)\n",
        "# val_acc = accuracy_score(y_val, y_val_pred)\n",
        "# test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "graph = Source(export_graphviz(dt, out_file=None, max_depth = 1, feature_names=feature_names))\n",
        "graph.format = 'png'\n",
        "graph.render('dt', view=True)"
      ],
      "metadata": {
        "id": "4ZUA1M3rwjFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6"
      ],
      "metadata": {
        "id": "LbYRCrU2vcTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the logistic regression object\n",
        "LogReg = LogisticRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "LogReg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the train, validation, and test sets\n",
        "y_train_pred = LogReg.predict(X_train)\n",
        "y_val_pred = LogReg.predict(X_valid)\n",
        "y_test_pred = LogReg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy scores\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "val_acc = accuracy_score(y_valid, y_val_pred)\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Train accuracy: \", train_acc)\n",
        "print(\"Validation accuracy: \", val_acc)\n",
        "print(\"Test accuracy: \", test_acc)"
      ],
      "metadata": {
        "id": "HSnizzEbyapq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}